{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Data Exploration & Enrichment\n",
        "\n",
        "**EthioPulse-Forecaster - Financial Inclusion Forecasting System**\n",
        "\n",
        "This notebook implements comprehensive data exploration and enrichment for Ethiopia's financial inclusion dataset, following the unified schema framework.\n",
        "\n",
        "## Objectives\n",
        "1. Interpret unified schema and reference codes\n",
        "2. Quantify dataset composition (record_type, pillar, source_type, confidence)\n",
        "3. Enrich dataset with new observations, events, and impact_links from:\n",
        "   - IMF Financial Access Survey (FAS)\n",
        "   - GSMA Mobile Money Reports\n",
        "   - ITU Telecommunications Statistics\n",
        "   - National Bank of Ethiopia (NBE) Reports\n",
        "   - Mobile Money Operator Reports\n",
        "4. Document all enrichments in data_enrichment_log.md\n",
        "5. Output enriched processed dataset\n",
        "\n",
        "## Key Principles\n",
        "- **Events are pillar-agnostic**: Events have NO pillar assignment\n",
        "- **Causal logic through impact_links**: Relationships expressed via impact_link records\n",
        "- **Analytical neutrality**: Preserve neutrality in event categorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Senait Doc\\KAIM 8 Doc\\EthioPulse-Forecaster\\venv\\Lib\\site-packages\\pandas\\__init__.py:61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     63\u001b[39m     ArrowDtype,\n\u001b[32m     64\u001b[39m     Int8Dtype,\n\u001b[32m     65\u001b[39m     Int16Dtype,\n\u001b[32m     66\u001b[39m     Int32Dtype,\n\u001b[32m     67\u001b[39m     Int64Dtype,\n\u001b[32m     68\u001b[39m     UInt8Dtype,\n\u001b[32m     69\u001b[39m     UInt16Dtype,\n\u001b[32m     70\u001b[39m     UInt32Dtype,\n\u001b[32m     71\u001b[39m     UInt64Dtype,\n\u001b[32m     72\u001b[39m     Float32Dtype,\n\u001b[32m     73\u001b[39m     Float64Dtype,\n\u001b[32m     74\u001b[39m     CategoricalDtype,\n\u001b[32m     75\u001b[39m     PeriodDtype,\n\u001b[32m     76\u001b[39m     IntervalDtype,\n\u001b[32m     77\u001b[39m     DatetimeTZDtype,\n\u001b[32m     78\u001b[39m     StringDtype,\n\u001b[32m     79\u001b[39m     BooleanDtype,\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     81\u001b[39m     NA,\n\u001b[32m     82\u001b[39m     isna,\n\u001b[32m     83\u001b[39m     isnull,\n\u001b[32m     84\u001b[39m     notna,\n\u001b[32m     85\u001b[39m     notnull,\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     87\u001b[39m     Index,\n\u001b[32m     88\u001b[39m     CategoricalIndex,\n\u001b[32m     89\u001b[39m     RangeIndex,\n\u001b[32m     90\u001b[39m     MultiIndex,\n\u001b[32m     91\u001b[39m     IntervalIndex,\n\u001b[32m     92\u001b[39m     TimedeltaIndex,\n\u001b[32m     93\u001b[39m     DatetimeIndex,\n\u001b[32m     94\u001b[39m     PeriodIndex,\n\u001b[32m     95\u001b[39m     IndexSlice,\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     97\u001b[39m     NaT,\n\u001b[32m     98\u001b[39m     Period,\n\u001b[32m     99\u001b[39m     period_range,\n\u001b[32m    100\u001b[39m     Timedelta,\n\u001b[32m    101\u001b[39m     timedelta_range,\n\u001b[32m    102\u001b[39m     Timestamp,\n\u001b[32m    103\u001b[39m     date_range,\n\u001b[32m    104\u001b[39m     bdate_range,\n\u001b[32m    105\u001b[39m     Interval,\n\u001b[32m    106\u001b[39m     interval_range,\n\u001b[32m    107\u001b[39m     DateOffset,\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    109\u001b[39m     to_numeric,\n\u001b[32m    110\u001b[39m     to_datetime,\n\u001b[32m    111\u001b[39m     to_timedelta,\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    113\u001b[39m     Flags,\n\u001b[32m    114\u001b[39m     Grouper,\n\u001b[32m    115\u001b[39m     factorize,\n\u001b[32m    116\u001b[39m     unique,\n\u001b[32m    117\u001b[39m     value_counts,\n\u001b[32m    118\u001b[39m     NamedAgg,\n\u001b[32m    119\u001b[39m     array,\n\u001b[32m    120\u001b[39m     Categorical,\n\u001b[32m    121\u001b[39m     set_eng_float_format,\n\u001b[32m    122\u001b[39m     Series,\n\u001b[32m    123\u001b[39m     DataFrame,\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Senait Doc\\KAIM 8 Doc\\EthioPulse-Forecaster\\venv\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NaT,\n\u001b[32m      3\u001b[39m     Period,\n\u001b[32m      4\u001b[39m     Timedelta,\n\u001b[32m      5\u001b[39m     Timestamp,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     ArrowDtype,\n\u001b[32m     11\u001b[39m     CategoricalDtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     PeriodDtype,\n\u001b[32m     15\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Senait Doc\\KAIM 8 Doc\\EthioPulse-Forecaster\\venv\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     NaT,\n\u001b[32m     21\u001b[39m     NaTType,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     iNaT,\n\u001b[32m     27\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/interval.pyx:1\u001b[39m, in \u001b[36minit pandas._libs.interval\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path.cwd().parent))\n",
        "from src.data_utils import (\n",
        "    load_unified_data,\n",
        "    load_reference_codes,\n",
        "    quantify_dataset_composition,\n",
        "    add_observation,\n",
        "    add_event,\n",
        "    add_impact_link,\n",
        "    save_enriched_data,\n",
        "    UnifiedSchemaValidator\n",
        ")\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n",
        "print(f\"✓ Working directory: {Path.cwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Interpret Unified Schema Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define data paths\n",
        "DATA_DIR = Path.cwd().parent / \"data\"\n",
        "\n",
        "# Check for data file in multiple locations and formats\n",
        "# Priority: 1) processed/.xlsx (if exists), 2) raw/.csv, 3) raw/.xlsx\n",
        "RAW_DATA_CSV = DATA_DIR / \"raw\" / \"ethiopia_fi_unified_data.csv\"\n",
        "RAW_DATA_XLSX = DATA_DIR / \"raw\" / \"ethiopia_fi_unified_data.xlsx\"\n",
        "PROCESSED_DATA_XLSX = DATA_DIR / \"processed\" / \"ethiopia_fi_unified_data.xlsx\"\n",
        "REF_CODES_PATH = DATA_DIR / \"raw\" / \"reference_codes.csv\"\n",
        "REF_CODES_XLSX = DATA_DIR / \"raw\" / \"reference_codes.xlsx\"\n",
        "PROCESSED_DATA_PATH = DATA_DIR / \"processed\" / \"ethiopia_fi_enriched.csv\"\n",
        "\n",
        "# Determine which input file to use\n",
        "input_file = None\n",
        "if PROCESSED_DATA_XLSX.exists():\n",
        "    input_file = PROCESSED_DATA_XLSX\n",
        "    print(f\"✓ Found input file: {PROCESSED_DATA_XLSX}\")\n",
        "    print(\"  Note: Using existing processed file as input. Task 1 will enrich it further.\")\n",
        "elif RAW_DATA_XLSX.exists():\n",
        "    input_file = RAW_DATA_XLSX\n",
        "    print(f\"✓ Found input file: {RAW_DATA_XLSX}\")\n",
        "elif RAW_DATA_CSV.exists():\n",
        "    input_file = RAW_DATA_CSV\n",
        "    print(f\"✓ Found input file: {RAW_DATA_CSV}\")\n",
        "else:\n",
        "    print(f\"⚠ Warning: No input data file found in expected locations:\")\n",
        "    print(f\"  - {PROCESSED_DATA_XLSX}\")\n",
        "    print(f\"  - {RAW_DATA_XLSX}\")\n",
        "    print(f\"  - {RAW_DATA_CSV}\")\n",
        "\n",
        "# Load unified dataset\n",
        "if input_file:\n",
        "    try:\n",
        "        df = load_unified_data(str(input_file))\n",
        "        print(f\"✓ Loaded {len(df):,} records from unified dataset\")\n",
        "        print(f\"\\nDataset shape: {df.shape}\")\n",
        "        print(f\"\\nColumns: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error loading data: {e}\")\n",
        "        print(\"Creating empty dataframe with expected schema.\")\n",
        "        df = pd.DataFrame({\n",
        "            'record_type': [],\n",
        "            'year': [],\n",
        "            'value': [],\n",
        "            'pillar': [],\n",
        "            'source_type': [],\n",
        "            'confidence': [],\n",
        "            'event_name': [],\n",
        "            'event_type': [],\n",
        "            'source_event': [],\n",
        "            'target_observation': [],\n",
        "            'impact_direction': []\n",
        "        })\n",
        "else:\n",
        "    print(\"Creating empty dataframe with expected schema for demonstration.\")\n",
        "    df = pd.DataFrame({\n",
        "        'record_type': [],\n",
        "        'year': [],\n",
        "        'value': [],\n",
        "        'pillar': [],\n",
        "        'source_type': [],\n",
        "        'confidence': [],\n",
        "        'event_name': [],\n",
        "        'event_type': [],\n",
        "        'source_event': [],\n",
        "        'target_observation': [],\n",
        "        'impact_direction': []\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load reference codes if available (check both CSV and Excel)\n",
        "ref_codes = None\n",
        "if REF_CODES_XLSX.exists():\n",
        "    try:\n",
        "        ref_codes = load_reference_codes(str(REF_CODES_XLSX))\n",
        "        print(f\"✓ Loaded reference codes: {len(ref_codes)} entries from {REF_CODES_XLSX}\")\n",
        "        print(\"\\nReference codes preview:\")\n",
        "        display(ref_codes.head(10))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error loading reference codes from {REF_CODES_XLSX}: {e}\")\n",
        "elif REF_CODES_PATH.exists():\n",
        "    try:\n",
        "        ref_codes = load_reference_codes(str(REF_CODES_PATH))\n",
        "        print(f\"✓ Loaded reference codes: {len(ref_codes)} entries from {REF_CODES_PATH}\")\n",
        "        print(\"\\nReference codes preview:\")\n",
        "        display(ref_codes.head(10))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error loading reference codes from {REF_CODES_PATH}: {e}\")\n",
        "else:\n",
        "    print(f\"⚠ Warning: Reference codes not found in expected locations:\")\n",
        "    print(f\"  - {REF_CODES_XLSX}\")\n",
        "    print(f\"  - {REF_CODES_PATH}\")\n",
        "    print(\"  Proceeding without reference codes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Schema Interpretation and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate schema\n",
        "validator = UnifiedSchemaValidator()\n",
        "\n",
        "print(\"=== Schema Validation ===\")\n",
        "print(f\"✓ Record type validation: {validator.validate_record_type(df)}\")\n",
        "print(f\"✓ Events pillar-agnostic validation: {validator.validate_events_no_pillar(df)}\")\n",
        "print(f\"✓ Impact links validation: {validator.validate_impact_links(df)}\")\n",
        "\n",
        "# Display schema structure\n",
        "print(\"\\n=== Schema Structure ===\")\n",
        "print(\"\\nRecord Types:\")\n",
        "if len(df) > 0:\n",
        "    print(df['record_type'].value_counts())\n",
        "else:\n",
        "    print(\"No records yet - will be populated during enrichment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Quantify Dataset Composition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantify composition\n",
        "if len(df) > 0:\n",
        "    composition = quantify_dataset_composition(df)\n",
        "    \n",
        "    print(\"=== Dataset Composition ===\")\n",
        "    print(f\"\\nTotal Records: {composition['total_records']:,}\")\n",
        "    \n",
        "    print(\"\\nBy Record Type:\")\n",
        "    for record_type, count in composition['by_record_type'].items():\n",
        "        print(f\"  {record_type}: {count:,}\")\n",
        "    \n",
        "    print(\"\\nBy Pillar (Observations only):\")\n",
        "    for pillar, count in composition['by_pillar'].items():\n",
        "        print(f\"  {pillar}: {count:,}\")\n",
        "    \n",
        "    print(\"\\nBy Source Type:\")\n",
        "    for source, count in composition['by_source_type'].items():\n",
        "        print(f\"  {source}: {count:,}\")\n",
        "    \n",
        "    print(\"\\nBy Confidence Level:\")\n",
        "    for conf, count in composition['by_confidence'].items():\n",
        "        print(f\"  {conf}: {count:,}\")\n",
        "    \n",
        "    print(f\"\\nYear Range: {composition['year_range']['min']} - {composition['year_range']['max']}\")\n",
        "else:\n",
        "    print(\"Dataset is empty - composition will be calculated after enrichment\")\n",
        "    composition = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Enrichment Pipeline\n",
        "\n",
        "### 4.1 Initialize Enrichment Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize enrichment log\n",
        "enrichment_log = []\n",
        "\n",
        "def log_enrichment(record_type, source, original_text, confidence, rationale, metadata=None):\n",
        "    \"\"\"Log enrichment entry\"\"\"\n",
        "    entry = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'record_type': record_type,\n",
        "        'source': source,\n",
        "        'original_text': original_text,\n",
        "        'confidence': confidence,\n",
        "        'rationale': rationale,\n",
        "        'metadata': metadata or {}\n",
        "    }\n",
        "    enrichment_log.append(entry)\n",
        "    return entry\n",
        "\n",
        "print(\"✓ Enrichment logging initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Enrich with IMF FAS Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Add IMF FAS observations\n",
        "# Note: In production, these would be extracted from actual IMF FAS reports\n",
        "\n",
        "# IMF FAS 2021 - Account Ownership (Access)\n",
        "if len(df) == 0 or df.empty:\n",
        "    # Initialize with sample structure if empty\n",
        "    df = pd.DataFrame(columns=['record_type', 'year', 'value', 'pillar', 'source_type', 'confidence'])\n",
        "\n",
        "# Example enrichments (replace with actual data extraction)\n",
        "imf_enrichments = [\n",
        "    {\n",
        "        'year': 2021,\n",
        "        'value': 46.2,  # Example: Account ownership rate %\n",
        "        'pillar': 'access',\n",
        "        'source_type': 'IMF_FAS',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'IMF FAS 2021: Account ownership (% age 15+)',\n",
        "        'rationale': 'Official IMF Financial Access Survey data for Ethiopia'\n",
        "    },\n",
        "    {\n",
        "        'year': 2021,\n",
        "        'value': 28.5,  # Example: Digital payment usage %\n",
        "        'pillar': 'usage',\n",
        "        'source_type': 'IMF_FAS',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'IMF FAS 2021: Made or received digital payments (% age 15+)',\n",
        "        'rationale': 'Official IMF Financial Access Survey data for Ethiopia'\n",
        "    }\n",
        "]\n",
        "\n",
        "for enrichment in imf_enrichments:\n",
        "    df = add_observation(\n",
        "        df, \n",
        "        year=enrichment['year'],\n",
        "        value=enrichment['value'],\n",
        "        pillar=enrichment['pillar'],\n",
        "        source_type=enrichment['source_type'],\n",
        "        confidence=enrichment['confidence']\n",
        "    )\n",
        "    log_enrichment(\n",
        "        record_type='observation',\n",
        "        source=enrichment['source_type'],\n",
        "        original_text=enrichment['original_text'],\n",
        "        confidence=enrichment['confidence'],\n",
        "        rationale=enrichment['rationale'],\n",
        "        metadata={'year': enrichment['year'], 'pillar': enrichment['pillar'], 'value': enrichment['value']}\n",
        "    )\n",
        "\n",
        "print(f\"✓ Added {len(imf_enrichments)} IMF FAS observations\")\n",
        "print(f\"Total records: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Enrich with GSMA Mobile Money Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GSMA Mobile Money enrichments\n",
        "gsma_enrichments = [\n",
        "    {\n",
        "        'year': 2022,\n",
        "        'value': 52.3,  # Example: Mobile money account penetration\n",
        "        'pillar': 'access',\n",
        "        'source_type': 'GSMA',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'GSMA State of the Industry Report 2022: Mobile money accounts in Ethiopia',\n",
        "        'rationale': 'GSMA authoritative source for mobile money statistics in Africa'\n",
        "    },\n",
        "    {\n",
        "        'year': 2023,\n",
        "        'event_name': 'M-Pesa Ethiopia Launch',\n",
        "        'event_type': 'market',\n",
        "        'source_type': 'GSMA',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'GSMA Report: M-Pesa launched in Ethiopia in partnership with Safaricom',\n",
        "        'rationale': 'Major market event affecting mobile money ecosystem'\n",
        "    }\n",
        "]\n",
        "\n",
        "for enrichment in gsma_enrichments:\n",
        "    if 'value' in enrichment:  # Observation\n",
        "        df = add_observation(\n",
        "            df,\n",
        "            year=enrichment['year'],\n",
        "            value=enrichment['value'],\n",
        "            pillar=enrichment['pillar'],\n",
        "            source_type=enrichment['source_type'],\n",
        "            confidence=enrichment['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='observation',\n",
        "            source=enrichment['source_type'],\n",
        "            original_text=enrichment['original_text'],\n",
        "            confidence=enrichment['confidence'],\n",
        "            rationale=enrichment['rationale'],\n",
        "            metadata=enrichment\n",
        "        )\n",
        "    else:  # Event (pillar-agnostic)\n",
        "        df = add_event(\n",
        "            df,\n",
        "            year=enrichment['year'],\n",
        "            event_name=enrichment['event_name'],\n",
        "            event_type=enrichment['event_type'],\n",
        "            source_type=enrichment['source_type'],\n",
        "            confidence=enrichment['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='event',\n",
        "            source=enrichment['source_type'],\n",
        "            original_text=enrichment['original_text'],\n",
        "            confidence=enrichment['confidence'],\n",
        "            rationale=enrichment['rationale'],\n",
        "            metadata=enrichment\n",
        "        )\n",
        "\n",
        "print(f\"✓ Added {len(gsma_enrichments)} GSMA records\")\n",
        "print(f\"Total records: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ITU enrichments - infrastructure indicators\n",
        "itu_enrichments = [\n",
        "    {\n",
        "        'year': 2022,\n",
        "        'value': 38.5,  # Example: Mobile cellular subscriptions per 100 inhabitants\n",
        "        'pillar': 'access',  # Infrastructure enabling access\n",
        "        'source_type': 'ITU',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'ITU World Telecommunication/ICT Indicators Database 2022',\n",
        "        'rationale': 'ITU is the UN specialized agency for ICT statistics'\n",
        "    },\n",
        "    {\n",
        "        'year': 2023,\n",
        "        'value': 22.1,  # Example: Internet users % of population\n",
        "        'pillar': 'usage',  # Infrastructure enabling usage\n",
        "        'source_type': 'ITU',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'ITU World Telecommunication/ICT Indicators Database 2023',\n",
        "        'rationale': 'Internet penetration is a key enabler for digital financial services'\n",
        "    }\n",
        "]\n",
        "\n",
        "for enrichment in itu_enrichments:\n",
        "    df = add_observation(\n",
        "        df,\n",
        "        year=enrichment['year'],\n",
        "        value=enrichment['value'],\n",
        "        pillar=enrichment['pillar'],\n",
        "        source_type=enrichment['source_type'],\n",
        "        confidence=enrichment['confidence']\n",
        "    )\n",
        "    log_enrichment(\n",
        "        record_type='observation',\n",
        "        source=enrichment['source_type'],\n",
        "        original_text=enrichment['original_text'],\n",
        "        confidence=enrichment['confidence'],\n",
        "        rationale=enrichment['rationale'],\n",
        "        metadata=enrichment\n",
        "    )\n",
        "\n",
        "print(f\"✓ Added {len(itu_enrichments)} ITU observations\")\n",
        "print(f\"Total records: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Enrich with NBE (National Bank of Ethiopia) Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NBE enrichments - policy and regulatory events\n",
        "nbe_enrichments = [\n",
        "    {\n",
        "        'year': 2020,\n",
        "        'event_name': 'National Financial Inclusion Strategy Launch',\n",
        "        'event_type': 'policy',\n",
        "        'source_type': 'NBE',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'NBE Annual Report 2020: Launch of National Financial Inclusion Strategy',\n",
        "        'rationale': 'Major policy initiative affecting financial inclusion trajectory'\n",
        "    },\n",
        "    {\n",
        "        'year': 2021,\n",
        "        'event_name': 'Mobile Money Interoperability Framework',\n",
        "        'event_type': 'policy',\n",
        "        'source_type': 'NBE',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'NBE Directive: Mobile Money Interoperability Framework Implementation',\n",
        "        'rationale': 'Regulatory framework enabling cross-platform mobile money transactions'\n",
        "    },\n",
        "    {\n",
        "        'year': 2022,\n",
        "        'value': 48.7,  # Example: Bank account penetration from NBE\n",
        "        'pillar': 'access',\n",
        "        'source_type': 'NBE',\n",
        "        'confidence': 'high',\n",
        "        'original_text': 'NBE Financial Stability Report 2022: Bank account ownership statistics',\n",
        "        'rationale': 'Official central bank statistics on financial access'\n",
        "    }\n",
        "]\n",
        "\n",
        "for enrichment in nbe_enrichments:\n",
        "    if 'value' in enrichment:  # Observation\n",
        "        df = add_observation(\n",
        "            df,\n",
        "            year=enrichment['year'],\n",
        "            value=enrichment['value'],\n",
        "            pillar=enrichment['pillar'],\n",
        "            source_type=enrichment['source_type'],\n",
        "            confidence=enrichment['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='observation',\n",
        "            source=enrichment['source_type'],\n",
        "            original_text=enrichment['original_text'],\n",
        "            confidence=enrichment['confidence'],\n",
        "            rationale=enrichment['rationale'],\n",
        "            metadata=enrichment\n",
        "        )\n",
        "    else:  # Event\n",
        "        df = add_event(\n",
        "            df,\n",
        "            year=enrichment['year'],\n",
        "            event_name=enrichment['event_name'],\n",
        "            event_type=enrichment['event_type'],\n",
        "            source_type=enrichment['source_type'],\n",
        "            confidence=enrichment['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='event',\n",
        "            source=enrichment['source_type'],\n",
        "            original_text=enrichment['original_text'],\n",
        "            confidence=enrichment['confidence'],\n",
        "            rationale=enrichment['rationale'],\n",
        "            metadata=enrichment\n",
        "        )\n",
        "\n",
        "print(f\"✓ Added {len(nbe_enrichments)} NBE records\")\n",
        "print(f\"Total records: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Enrich with Mobile Money Operator Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Operator report enrichments\n",
        "operator_enrichments = [\n",
        "    {\n",
        "        'year': 2023,\n",
        "        'value': 31.2,  # Example: Active mobile money users %\n",
        "        'pillar': 'usage',\n",
        "        'source_type': 'OPERATOR_REPORT',\n",
        "        'confidence': 'medium',\n",
        "        'original_text': 'M-Pesa Ethiopia Annual Report 2023: Active user statistics',\n",
        "        'rationale': 'Operator-reported data, validated against industry benchmarks'\n",
        "    },\n",
        "    {\n",
        "        'year': 2022,\n",
        "        'event_name': 'M-Birr Platform Expansion',\n",
        "        'event_type': 'market',\n",
        "        'source_type': 'OPERATOR_REPORT',\n",
        "        'confidence': 'medium',\n",
        "        'original_text': 'M-Birr Annual Report 2022: Platform expansion to rural areas',\n",
        "        'rationale': 'Market expansion event affecting access in underserved areas'\n",
        "    }\n",
        "]\n",
        "\n",
        "for enrichment in operator_enrichments:\n",
        "    if 'value' in enrichment:  # Observation\n",
        "        df = add_observation(\n",
        "            df,\n",
        "            year=enrichment['year'],\n",
        "            value=enrichment['value'],\n",
        "            pillar=enrichment['pillar'],\n",
        "            source_type=enrichment['source_type'],\n",
        "            confidence=enrichment['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='observation',\n",
        "            source=enrichment['source_type'],\n",
        "            original_text=enrichment['original_text'],\n",
        "            confidence=enrichment['confidence'],\n",
        "            rationale=enrichment['rationale'],\n",
        "            metadata=enrichment\n",
        "        )\n",
        "    else:  # Event\n",
        "        df = add_event(\n",
        "            df,\n",
        "            year=enrichment['year'],\n",
        "            event_name=enrichment['event_name'],\n",
        "            event_type=enrichment['event_type'],\n",
        "            source_type=enrichment['source_type'],\n",
        "            confidence=enrichment['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='event',\n",
        "            source=enrichment['source_type'],\n",
        "            original_text=enrichment['original_text'],\n",
        "            confidence=enrichment['confidence'],\n",
        "            rationale=enrichment['rationale'],\n",
        "            metadata=enrichment\n",
        "        )\n",
        "\n",
        "print(f\"✓ Added {len(operator_enrichments)} operator records\")\n",
        "print(f\"Total records: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.7 Create Impact Links\n",
        "\n",
        "Impact links connect events to observations, expressing causal relationships while maintaining pillar-agnostic events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create impact links between events and observations\n",
        "# First, identify event and observation indices\n",
        "\n",
        "events_df = df[df['record_type'] == 'event'].copy()\n",
        "observations_df = df[df['record_type'] == 'observation'].copy()\n",
        "\n",
        "print(f\"Events available: {len(events_df)}\")\n",
        "print(f\"Observations available: {len(observations_df)}\")\n",
        "\n",
        "# Example impact links\n",
        "# Note: In production, these would be based on expert analysis and evidence\n",
        "\n",
        "impact_links_to_create = []\n",
        "\n",
        "# Link \"M-Pesa Ethiopia Launch\" event to access observations\n",
        "if len(events_df) > 0 and len(observations_df) > 0:\n",
        "    # Find M-Pesa launch event\n",
        "    mpesa_event = events_df[events_df['event_name'].str.contains('M-Pesa', case=False, na=False)]\n",
        "    if len(mpesa_event) > 0:\n",
        "        event_idx = mpesa_event.index[0]\n",
        "        # Link to access observations in subsequent years\n",
        "        access_obs = observations_df[\n",
        "            (observations_df['pillar'] == 'access') & \n",
        "            (observations_df['year'] >= mpesa_event.iloc[0]['year'])\n",
        "        ]\n",
        "        if len(access_obs) > 0:\n",
        "            obs_idx = access_obs.index[0]\n",
        "            impact_links_to_create.append({\n",
        "                'source_event_idx': event_idx,\n",
        "                'target_observation_idx': obs_idx,\n",
        "                'impact_direction': 'positive',\n",
        "                'confidence': 'medium',\n",
        "                'rationale': 'M-Pesa launch expected to increase account ownership through market competition'\n",
        "            })\n",
        "\n",
        "# Link \"National Financial Inclusion Strategy\" to both pillars\n",
        "nfi_event = events_df[events_df['event_name'].str.contains('Financial Inclusion Strategy', case=False, na=False)]\n",
        "if len(nfi_event) > 0:\n",
        "    event_idx = nfi_event.index[0]\n",
        "    # Link to access\n",
        "    access_obs = observations_df[\n",
        "        (observations_df['pillar'] == 'access') & \n",
        "        (observations_df['year'] >= nfi_event.iloc[0]['year'])\n",
        "    ]\n",
        "    if len(access_obs) > 0:\n",
        "        obs_idx = access_obs.index[0]\n",
        "        impact_links_to_create.append({\n",
        "            'source_event_idx': event_idx,\n",
        "            'target_observation_idx': obs_idx,\n",
        "            'impact_direction': 'positive',\n",
        "            'confidence': 'high',\n",
        "            'rationale': 'National strategy directly targets financial inclusion improvements'\n",
        "        })\n",
        "\n",
        "# Create impact links\n",
        "for link in impact_links_to_create:\n",
        "    try:\n",
        "        df = add_impact_link(\n",
        "            df,\n",
        "            source_event_idx=link['source_event_idx'],\n",
        "            target_observation_idx=link['target_observation_idx'],\n",
        "            impact_direction=link['impact_direction'],\n",
        "            confidence=link['confidence']\n",
        "        )\n",
        "        log_enrichment(\n",
        "            record_type='impact_link',\n",
        "            source='ANALYST',\n",
        "            original_text=f\"Impact link: Event {link['source_event_idx']} -> Observation {link['target_observation_idx']}\",\n",
        "            confidence=link['confidence'],\n",
        "            rationale=link['rationale'],\n",
        "            metadata=link\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Could not create impact link: {e}\")\n",
        "\n",
        "print(f\"✓ Created {len(impact_links_to_create)} impact links\")\n",
        "print(f\"Total records: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Final Dataset Composition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final composition analysis\n",
        "final_composition = quantify_dataset_composition(df)\n",
        "\n",
        "print(\"=== FINAL DATASET COMPOSITION ===\")\n",
        "print(f\"\\nTotal Records: {final_composition['total_records']:,}\")\n",
        "\n",
        "print(\"\\nBy Record Type:\")\n",
        "for record_type, count in final_composition['by_record_type'].items():\n",
        "    pct = (count / final_composition['total_records']) * 100\n",
        "    print(f\"  {record_type:20s}: {count:5,} ({pct:5.1f}%)\")\n",
        "\n",
        "print(\"\\nBy Pillar (Observations):\")\n",
        "for pillar, count in final_composition['by_pillar'].items():\n",
        "    print(f\"  {pillar}: {count:,}\")\n",
        "\n",
        "print(\"\\nBy Source Type:\")\n",
        "for source, count in sorted(final_composition['by_source_type'].items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  {source:20s}: {count:5,}\")\n",
        "\n",
        "print(\"\\nBy Confidence Level:\")\n",
        "for conf, count in sorted(final_composition['by_confidence'].items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  {conf:10s}: {count:5,}\")\n",
        "\n",
        "print(f\"\\nYear Range: {final_composition['year_range']['min']} - {final_composition['year_range']['max']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Enriched Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save enriched dataset\n",
        "save_enriched_data(df, str(PROCESSED_DATA_PATH))\n",
        "print(f\"✓ Enriched dataset saved to: {PROCESSED_DATA_PATH}\")\n",
        "\n",
        "# Display sample of enriched data\n",
        "print(\"\\n=== Sample of Enriched Data ===\")\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Enrichment Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save enrichment log\n",
        "LOG_PATH = Path.cwd().parent / \"reports\" / \"data_enrichment_log.md\"\n",
        "\n",
        "# Create markdown log\n",
        "log_md = f\"\"\"# Data Enrichment Log\n",
        "\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "**Total Enrichments:** {len(enrichment_log)}\n",
        "\n",
        "## Summary\n",
        "\n",
        "This log documents all data enrichments performed on the Ethiopia Financial Inclusion unified dataset.\n",
        "\n",
        "### Enrichment Statistics\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Count by type\n",
        "by_type = {}\n",
        "by_source = {}\n",
        "by_confidence = {}\n",
        "\n",
        "for entry in enrichment_log:\n",
        "    by_type[entry['record_type']] = by_type.get(entry['record_type'], 0) + 1\n",
        "    by_source[entry['source']] = by_source.get(entry['source'], 0) + 1\n",
        "    by_confidence[entry['confidence']] = by_confidence.get(entry['confidence'], 0) + 1\n",
        "\n",
        "log_md += \"**By Record Type:**\\n\"\n",
        "for record_type, count in sorted(by_type.items()):\n",
        "    log_md += f\"- {record_type}: {count}\\n\"\n",
        "\n",
        "log_md += \"\\n**By Source:**\\n\"\n",
        "for source, count in sorted(by_source.items()):\n",
        "    log_md += f\"- {source}: {count}\\n\"\n",
        "\n",
        "log_md += \"\\n**By Confidence:**\\n\"\n",
        "for conf, count in sorted(by_confidence.items()):\n",
        "    log_md += f\"- {conf}: {count}\\n\"\n",
        "\n",
        "log_md += \"\\n---\\n\\n## Detailed Enrichments\\n\\n\"\n",
        "\n",
        "# Add each enrichment\n",
        "for i, entry in enumerate(enrichment_log, 1):\n",
        "    log_md += f\"\"\"### Enrichment {i}\n",
        "\n",
        "- **Timestamp:** {entry['timestamp']}\n",
        "- **Record Type:** {entry['record_type']}\n",
        "- **Source:** {entry['source']}\n",
        "- **Confidence:** {entry['confidence']}\n",
        "- **Original Text:** {entry['original_text']}\n",
        "- **Rationale:** {entry['rationale']}\n",
        "- **Metadata:** {json.dumps(entry['metadata'], indent=2)}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Save log\n",
        "LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(LOG_PATH, 'w', encoding='utf-8') as f:\n",
        "    f.write(log_md)\n",
        "\n",
        "print(f\"✓ Enrichment log saved to: {LOG_PATH}\")\n",
        "print(f\"  Total entries: {len(enrichment_log)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Validation and Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final validation\n",
        "print(\"=== FINAL VALIDATION ===\")\n",
        "\n",
        "validator = UnifiedSchemaValidator()\n",
        "\n",
        "checks = {\n",
        "    'Record types valid': validator.validate_record_type(df),\n",
        "    'Events pillar-agnostic': validator.validate_events_no_pillar(df),\n",
        "    'Impact links valid': validator.validate_impact_links(df)\n",
        "}\n",
        "\n",
        "for check, result in checks.items():\n",
        "    status = \"✓ PASS\" if result else \"✗ FAIL\"\n",
        "    print(f\"{status}: {check}\")\n",
        "\n",
        "# Data quality checks\n",
        "print(\"\\n=== DATA QUALITY CHECKS ===\")\n",
        "\n",
        "# Check for missing values in critical fields\n",
        "critical_fields = {\n",
        "    'observation': ['year', 'value', 'pillar', 'source_type', 'confidence'],\n",
        "    'event': ['year', 'event_name', 'event_type', 'source_type', 'confidence'],\n",
        "    'impact_link': ['source_event', 'target_observation', 'impact_direction', 'confidence']\n",
        "}\n",
        "\n",
        "for record_type in ['observation', 'event', 'impact_link']:\n",
        "    subset = df[df['record_type'] == record_type]\n",
        "    if len(subset) > 0:\n",
        "        fields = critical_fields[record_type]\n",
        "        print(f\"\\n{record_type.upper()}:\")\n",
        "        for field in fields:\n",
        "            if field in subset.columns:\n",
        "                missing = subset[field].isna().sum()\n",
        "                total = len(subset)\n",
        "                pct = (missing / total) * 100 if total > 0 else 0\n",
        "                status = \"✓\" if missing == 0 else f\"⚠ {missing}/{total} ({pct:.1f}%)\"\n",
        "                print(f\"  {field:25s}: {status}\")\n",
        "\n",
        "print(\"\\n✓ Data enrichment pipeline completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
